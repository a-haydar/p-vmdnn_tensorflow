[generalSettings]

# Device setting. Either gpu or cpu depending on the system. GPU is highly recommended
device: /gpu:0

## Dataset
# The directory that contains the dataset
data_dir: ./dataset/
# The filename of the dataset
data_fn: icubOnScreen_4864_minMax1_2.npz

## Logging
# The directory for the log&network files. If it doesn't exist, it'll make a new directory
log_dir: ./log_dir/
# The name of the network file. In the log_dir, log_fn+epochNumber will be saved.
log_fn: netInform.ckpt

# Displaying the result on the screen. Every Nth epoch, the results (MSE, computation time) will be printed on the screen.
# Also, the loss will be (over) written at every Nth epoch in the loss.txt in log_dir directory.
print_epoch: 100

# Saving the network in the log directory. Every Nth epoch, the results (log_fn_epoch) will be saved in the log_dir.
saveNetwork_epoch: 1000

# The initial threshold for saving the result. This is to obtain the result from the epoch with the lowest loss
# The value itself will be updated during training.
loss_minTH = 0.01

## Loading the trained network (used for incremental training from the pre-trained network)
# If incremetalLearning is false (0), it initializes the variables and starts training.
# If incremetalLearning us true (1), it loads the trained network at the beginning.
# if it is set to true (1), restoreNetworkEpoch should be set to some epoch that you want to check
# Then, it will load log_fn+restoreNetworkEpoch file in the log_dir
incremetalLearning: False

# When incrementally learning / or checking the training result, specify the epoch number that you want to check.
restoreNetworkEpoch: 100000


[learningParameters]
# Learning Rate
#lrate: 0.001
lrate: 0.1

# The maximum number of training epoch
max_epoch: 100000

# Batch size
batch_size: 2

# Closed-loop Ratio. If it's 1.0, it is fully closed-loop. If it is 0.0, it is fully open-loop.
cl_ratio = 1.0

# Name of the Optimizer (adam, sgd)
optimizer = adam


[networkSettings]
## Lateral Connections between the pathways
# 1 (true): lateral connection, 0 (false): no lateral connection
enableLateral_high_visionToProp: 1
enableLateral_high_propToVision: 1
enableLateral_mid_visionToProp: 0
enableLateral_mid_propToVision: 0
enableLateral_low_visionToProp: 0
enableLateral_low_propToVision: 0

## Visual Pathway
# Unit: Number of Feature Maps
# Tau: Time Constant
# m_size_h: Height of Feature Map
# m_size_w: Width of Feature Map
# _convFilter_h: height of the filter for convolution input
# _convFilter_w: width of the filter for convolution input
# _convStride_h: stride (w.r.t. h) for convolution input
# _convStride_w: stride (w.r.t. w) for convolution input

# Vision Fast (Lower Level)
v1_unit: 4
v1_tau: 2.0
v1_msize_h: 44
v1_msize_w: 60
v1_convFilter_h: 5
v1_convFilter_w: 5
v1_convStride_h: 1
v1_convStride_w: 1

# Vision Mid (mid Level)
v2_unit: 8
v2_tau: 4.0
v2_msize_h: 21
v2_msize_w: 29
v2_convFilter_h: 4
v2_convFilter_w: 4
v2_convStride_h: 2
v2_convStride_w: 2


# Vision Slow (higher Level)
v3_unit: 12
v3_tau: 8.0
v3_msize_h: 9
v3_msize_w: 13
v3_convFilter_h: 5
v3_convFilter_w: 5
v3_convStride_h: 2
v3_convStride_w: 2


## Proprioceptive Pathway
# Unit: Number of neurons
# Tau: Time Constant

# Prop. Fast (Lower Level)
p1_unit: 30
p1_tau: 2.0

# Prop. Mid (mid Level)
p2_unit: 20
p2_tau: 4.0

# Prop. Slow (higher Level)
p3_unit: 10
p3_tau: 8.0
# Note that within the code, Prop. Slow (higher level) is handled as Vision layer (P-MSTRNN) with the size of 1 x 1 feature map.
p3_msize_h: 1
p3_msize_w: 1
p3_convFilter_h: 9
p3_convFilter_w: 13
p3_convStride_h: 1
p3_convStride_w: 1



#================================================================================
# Parameters for testing (Sensory entrainment & error regression)
[forTesting]
# The number of patterns used in the training process.
# To restore the network trained with the training dataset, we need to specify the number of patterns in the training dataset
originalNumberOfPrimitives: 2

# The name of the testing dataset. Note that this dataset should contain 1 pattern.
data_fn_testing: icubOnScreen_4864_minMax1_er_4.npz

# The P-VMDNN has 2 pathways (Vision & Proprioception).
# During the error regression scheme, we need to specify which prediction error should be minimized
# 1: Visual Prediction Error, 2: Proprioceptive Prediction Error 3: Both (Not yet tested)
lossType: 1

# During the ERS, the model's internal states are updated N times at each time step.
numIterations: 100

# The window size in the ERS
windowLength: 20

# For testing only. When true (1), if the error is smaller than erTH, the model will stop iteration and proceed to the next time step.
ers_adaptiveStopping: False
erTH: 0.00005


